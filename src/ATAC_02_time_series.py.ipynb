{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6bc9be1",
   "metadata": {},
   "source": [
    "# ATAC-seq - Time series analysis \n",
    "- recommendation: use multiple cores for the clustering part eg 32\n",
    "- goal: gene clusters with similar temporal behaviour\n",
    "- input: DAR results\n",
    "- output: gene clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ff1fb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sreichl/projects/bmdm-stim\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f5b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tslearn\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.clustering import silhouette_score\n",
    "from tslearn.metrics import cdist_dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65384f77-66f2-46b2-ba5f-5ccd77621f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import util functions\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join('src'))\n",
    "\n",
    "import utils_dimred_UMAP_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5d268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "dir_data = os.path.join('results', 'ATAC', 'all')\n",
    "dir_results=os.path.join(dir_data, 'time_series')\n",
    "metadata_path=os.path.join('metadata','ATAC_sample_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2917581",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dir_results):\n",
    "        os.mkdir(dir_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812dcd0",
   "metadata": {},
   "source": [
    "# load annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35efc95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load sample annotation\n",
    "annot = pd.read_csv(metadata_path, index_col=0, header=0,)\n",
    "print(annot.shape)\n",
    "annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694caa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load region annotation\n",
    "region_annot = pd.read_csv(os.path.join(dir_data,'consensus_regions_annotation.csv'), index_col=0, header=0,)\n",
    "print(region_annot.shape)\n",
    "region_annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ad5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = ['0h','2h', '4h', '6h', '8h','24h']\n",
    "treatments = list(annot['Treatment'].unique())\n",
    "treatments.remove('untreated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7383add",
   "metadata": {},
   "source": [
    "# prepare data, perform cluster analysis, plot & save results for each treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8be631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for treatment in treatments:\n",
    "    \n",
    "    ### make results directory\n",
    "    dir_treatment_results = os.path.join(dir_results, treatment)\n",
    "    if not os.path.exists(dir_treatment_results):\n",
    "            os.mkdir(dir_treatment_results)\n",
    "\n",
    "    ### load data per treatment\n",
    "    data = pd.read_csv(os.path.join(dir_data,'DEA','DEA_'+treatment+'.tsv'), header=0, sep='\\t', index_col='rn')\n",
    "    print(data.shape)\n",
    "    data.head()\n",
    "\n",
    "    ### generate time table = DEGs x time -> LFC values\n",
    "    df_list = []\n",
    "    for time in times:#annot['Treatment_time'].unique():\n",
    "        df_list.append(data.loc[data['group']==treatment+'_'+time,'logFC'])\n",
    "\n",
    "    time_table = pd.concat(df_list, axis=1)\n",
    "    time_table.columns = times\n",
    "\n",
    "    # fill 0h/untreated timepoint as zero-vector\n",
    "    time_table['0h'] = 0\n",
    "    print(time_table.shape)\n",
    "    time_table.head()\n",
    "\n",
    "    ### select genes of interest\n",
    "    LFC_cutoff=2\n",
    "\n",
    "    # very little signal in the C_albicans treatment (UV inactivated) -> less stringent gene selection\n",
    "    if treatment == 'C_albicans':\n",
    "        LFC_cutoff=1\n",
    "\n",
    "    genes_sig = data.loc[(data['adj.P.Val']<0.05) & (data['AveExpr']>0) & (data['logFC'].abs()>LFC_cutoff), ].index.unique() # most restrictive\n",
    "    print(len(genes_sig))\n",
    "\n",
    "    ### make plot of LFCs over time of all genes\n",
    "    plot_df = time_table.loc[genes_sig,].T\n",
    "    plot_df.plot.line(legend=False, alpha=0.1)\n",
    "    plt.savefig(\n",
    "        fname=os.path.join(dir_treatment_results, \"timecourse_allGenes_\"+treatment+\".svg\"),\n",
    "        format=\"svg\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    ### perform clustering with tslearn (30min/treatment with DTW metric, euclidean much faster)\n",
    "\n",
    "    # clustering configs\n",
    "    metric = \"euclidean\"\n",
    "    ks = list(range(2,11))+[15,20]\n",
    "    \n",
    "    silh_scores = pd.DataFrame(index=ks, columns=['silhouette'])\n",
    "\n",
    "    # prepare data as time-series for analysis\n",
    "    ts_data = to_time_series_dataset(time_table.loc[genes_sig,])\n",
    "    print(ts_data.shape)\n",
    "\n",
    "    for k in ks:\n",
    "        print(k)\n",
    "        \n",
    "        # make result folder per tested k\n",
    "        dir_treatment_results_k = os.path.join(dir_results, treatment, \"k_{}\".format(k))\n",
    "        if not os.path.exists(dir_treatment_results_k):\n",
    "            os.mkdir(dir_treatment_results_k)\n",
    "        \n",
    "        km = TimeSeriesKMeans(n_clusters=k, metric=metric, random_state=42, n_jobs=-1, verbose=False)\n",
    "        km.fit(ts_data)\n",
    "        #tmp_silh = silhouette_score(dtw_dist, km.labels_, metric=\"precomputed\", n_jobs=-1, verbose=False) ############## EXPERIMENT\n",
    "        silh = silhouette_score(ts_data, km.labels_, metric=metric, n_jobs=-1, verbose=False) ############## EXPERIMENT\n",
    "        silh_scores.loc[k,'silhouette']=silh\n",
    "\n",
    "        ### plot LFC over time for each gene cluster as visual validation\n",
    "\n",
    "        # plot all clusters and their center of LFCs over time of all genes\n",
    "        plt.figure(figsize=(6, math.ceil(k/3)*2), dpi=300)\n",
    "        for yi in np.unique(km.labels_):\n",
    "            plt.subplot(math.ceil(k/3), 3, yi+1)\n",
    "            for xx in ts_data[km.labels_ == yi]:\n",
    "                plt.plot(xx.ravel(), \"k-\", alpha=.1)\n",
    "                plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "                plt.title('Cluster {}\\n(n={})'.format((yi + 1), sum(km.labels_ == yi)))\n",
    "                plt.xticks(ticks=list(range(time_table.shape[1])), labels=time_table.columns.to_list())\n",
    "        #         plt.xlabel('time')\n",
    "        #         plt.ylabel('LFC')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            fname=os.path.join(dir_treatment_results_k, \"timecourse_clusters_\"+treatment+\".svg\"),\n",
    "            format=\"svg\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "        # make cluster center dataframe and plot\n",
    "        centers = pd.DataFrame()\n",
    "        plt.figure()\n",
    "        for label in np.unique(km.labels_):\n",
    "            plt.plot(km.cluster_centers_[label].ravel(), label='Cluster {} (n={})'.format((label + 1), sum(km.labels_ == label)))\n",
    "            centers = centers.append(pd.Series(km.cluster_centers_[label].ravel()), ignore_index=True)\n",
    "        centers.columns=time_table.columns\n",
    "        plt.xticks(ticks=list(range(time_table.shape[1])), labels=time_table.columns.to_list())\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('LFC')\n",
    "        plt.title('Cluster Centers silh={}'.format(round(silh,3)))\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            fname=os.path.join(dir_treatment_results_k, \"timecourse_clustercenters_\"+treatment+\".svg\"),\n",
    "            format=\"svg\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "        ### plot dimensionality reduced data (PCA & UMAP)\n",
    "\n",
    "        region_annot.loc[genes_sig,'cluster'] = km.labels_.astype(int)+1\n",
    "        # region_annot.loc[[gene not in genes_sig for gene in region_annot.index],'cluster'] = -1\n",
    "        region_annot['cluster'] =region_annot['cluster'].astype(str)\n",
    "\n",
    "        # plot PCA & UMAP again with final cluster labels and gene_biotype\n",
    "        dimred_UMAP_PCA.dimred_plot(data=time_table.loc[genes_sig,], \n",
    "                    annot=region_annot.loc[genes_sig,], \n",
    "                    variables=['cluster','homer_Gene Type'], \n",
    "                   label='{}_{}_timeseries'.format(treatment, str(len(genes_sig))),\n",
    "                    results_dir=os.path.join(dir_treatment_results_k),\n",
    "                   )\n",
    "        \n",
    "         ### save clustering results\n",
    "        # save clustering \n",
    "        pd.DataFrame([genes_sig, km.labels_.astype(int)+1]).T.to_csv(os.path.join(dir_treatment_results_k,  \"clustering_{}.csv\".format(treatment)))\n",
    "        # save cluster centers to csv\n",
    "        centers.to_csv(os.path.join(dir_treatment_results_k,  \"clustercenters_{}.csv\".format(treatment)))\n",
    "        # save model\n",
    "        km.to_pickle(os.path.join(dir_treatment_results_k,  \"model_{}.pickle\".format(treatment)))\n",
    "    \n",
    "    # save silhouette scores of treatment across tested ks\n",
    "    silh_scores.to_csv(os.path.join(dir_treatment_results, \"silhouette_scores_\"+treatment+\".csv\"))\n",
    "    \n",
    "    # plot silh scores across ks\n",
    "    silh_scores= silh_scores.apply(pd.to_numeric)\n",
    "    silh_scores.plot.line(figsize=(5,4),legend=False, xlabel='# of clusters (k)', ylabel='silhouette score', title='Silhouette scores of {} time-series clusters'.format(treatment))\n",
    "    plt.scatter(silh_scores.idxmax(), silh_scores.max(), marker='^', color='k')\n",
    "    plt.scatter(silh_scores.idxmin(), silh_scores.min(), marker='v', color='k')\n",
    "    plt.xticks(ticks=ks)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        fname=os.path.join(dir_treatment_results, \"silhouette_scores_\"+treatment+\".svg\"),\n",
    "        format=\"svg\",\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c3f8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_basics",
   "language": "python",
   "name": "basics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
